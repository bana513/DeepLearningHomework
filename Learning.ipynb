{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "\n",
    "# 5min BTC/USDT chart form Poloniex since 2017-01-01T00:00:00+00:00 till 2018-10-14T20:00:00+00:00\n",
    "with urllib.request.urlopen(\"https://poloniex.com/public?command=returnChartData&currencyPair=USDT_BTC&start=1483228800&end=1539547200&period=300\") as url:\n",
    "    data = json.loads(url.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': 1483228800, 'high': 965.00000066, 'low': 964.00000002, 'open': 965.00000055, 'close': 964.00000127, 'volume': 5398.83711674, 'quoteVolume': 5.59672254, 'weightedAverage': 964.64262399}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weightedAverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483228800</td>\n",
       "      <td>964.642624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1483229100</td>\n",
       "      <td>965.858035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1483229400</td>\n",
       "      <td>963.946565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1483229700</td>\n",
       "      <td>962.024978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1483230000</td>\n",
       "      <td>963.568648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  weightedAverage\n",
       "0  1483228800       964.642624\n",
       "1  1483229100       965.858035\n",
       "2  1483229400       963.946565\n",
       "3  1483229700       962.024978\n",
       "4  1483230000       963.568648"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "df = pd.DataFrame(data=data, columns=['date', 'weightedAverage'])\n",
    "        \n",
    "df = df.fillna(method='ffill')\n",
    "df.to_csv(\"poloniex_usdt_btc_20170101_weightedAverage_300.csv\", sep=\";\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375458\n"
     ]
    }
   ],
   "source": [
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dataframe into a numpy floating point array\n",
    "df_values = df.values\n",
    "timestamps = df_values[:, 0]\n",
    "dataset = df_values[:, 1].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (70%), cross validation (20%) and test (10%) set\n",
    "samples_num = dataset.shape[0]\n",
    "\n",
    "valid_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "dataset_train = dataset[0:int(samples_num * (1 - valid_split - test_split))]\n",
    "dataset_valid = dataset[int(samples_num * (1 - valid_split - test_split)):int(samples_num * (1 - test_split))]\n",
    "dataset_test = dataset[int(samples_num * (1 - test_split)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131410,)\n",
      "(37546,)\n",
      "(18773,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.shape)\n",
    "print(dataset_valid.shape)\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[964.64262399 965.85803538 963.94656468 962.02497756 963.56864844]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a training examples from year data with a timesteps window size\n",
    "\n",
    "def makeXy(data, timesteps):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(timesteps, data.shape[0]):\n",
    "        X.append(list(data[i-timesteps:i]))\n",
    "        y.append(data[i])\n",
    "        \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131410,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131410]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset_train.shape).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[-0.95438328]\n",
      " [-0.9541113 ]\n",
      " [-0.95453904]\n",
      " ...\n",
      " [ 0.3791661 ]\n",
      " [ 0.37897781]\n",
      " [ 0.37332536]]\n",
      "\n",
      "X_valid:\n",
      "[[0.37374208]\n",
      " [0.37158819]\n",
      " [0.36742356]\n",
      " ...\n",
      " [0.2704622 ]\n",
      " [0.27149772]\n",
      " [0.27376986]]\n",
      "\n",
      "X_test:\n",
      "[[0.27597285]\n",
      " [0.27707803]\n",
      " [0.27824451]\n",
      " ...\n",
      " [0.26215537]\n",
      " [0.2623948 ]\n",
      " [0.26275016]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler().fit(np.array(dataset_train).reshape(-1, 1))\n",
    "X_train = scaler.transform(np.array(dataset_train).reshape(-1, 1))\n",
    "X_valid = scaler.transform(np.array(dataset_valid).reshape(-1, 1))\n",
    "X_test = scaler.transform(np.array(dataset_test).reshape(-1, 1))\n",
    "\n",
    "# Saving scaler for prediction\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) \n",
    "\n",
    "print (\"X_train:\\n\" + str(X_train))\n",
    "print (\"\\nX_valid:\\n\" + str(X_valid))\n",
    "print (\"\\nX_test:\\n\" + str(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131390, 20, 1)\n",
      "(131390, 1)\n",
      "(131390, 20)\n",
      "(131390, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "timestep = 20 # Make decision from last 20 days\n",
    "\n",
    "# Create training examples\n",
    "\n",
    "train_X, train_y = makeXy(X_train, timestep)\n",
    "valid_X, valid_y = makeXy(X_valid, timestep)\n",
    "test_X, test_y = makeXy(X_test, timestep)\n",
    "    \n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0],-1)\n",
    "valid_X = valid_X.reshape(valid_X.shape[0],-1)\n",
    "test_X = test_X.reshape(test_X.shape[0],-1)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.95438328 -0.9541113  -0.95453904 -0.95496905 -0.95462361 -0.95422342\n",
      " -0.95477771 -0.9545387  -0.9546288  -0.95445073 -0.95421625 -0.95449726\n",
      " -0.95449726 -0.95411198 -0.95449726 -0.95449726 -0.95411418 -0.95411198\n",
      " -0.95411198 -0.95410895]\n",
      "[-0.95400951]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "# Set random seed to always predict the same values\n",
    "np.random.seed(1)\n",
    "set_random_seed(2) # Tensoflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving loss and acc values\n",
    "\n",
    "class TrainingHistory(Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.valid_losses = []\n",
    "        self.accs = []\n",
    "        self.valid_accs = []\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.valid_losses.append(logs.get('val_loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.valid_accs.append(logs.get('val_acc'))\n",
    "        self.epoch += 1\n",
    "            \n",
    "history = TrainingHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, activation='sigmoid', input_shape=(train_X.shape[1],)))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer= Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.save('model.h5') # Saving model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up early stopping and weight saving on actually best solutions\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience=30\n",
    "early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6570 samples, validate on 1877 samples\n",
      "Epoch 1/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.0635e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00006\n",
      "Epoch 2/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.6560e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00006\n",
      "Epoch 3/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.2614e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00006\n",
      "Epoch 4/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.9035e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00006\n",
      "Epoch 5/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.8952e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00006\n",
      "Epoch 6/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.7827e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00006\n",
      "Epoch 7/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.3512e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00006\n",
      "Epoch 8/2500\n",
      " - 2s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.1432e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00006\n",
      "Epoch 9/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.1936e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00006\n",
      "Epoch 10/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.0077e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00006\n",
      "Epoch 11/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.6188e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00006\n",
      "Epoch 12/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.2414e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00006\n",
      "Epoch 13/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.1052e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00006\n",
      "Epoch 14/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.4778e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00006\n",
      "Epoch 15/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.7870e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00006 to 0.00006, saving model to weights.hdf5\n",
      "Epoch 16/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.1488e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00006\n",
      "Epoch 17/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.1734e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00006\n",
      "Epoch 18/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.0169e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00006\n",
      "Epoch 19/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.4189e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00006 to 0.00004, saving model to weights.hdf5\n",
      "Epoch 20/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.7489e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00004\n",
      "Epoch 21/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.7482e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00004\n",
      "Epoch 22/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.7911e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00004\n",
      "Epoch 23/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.3001e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00004\n",
      "Epoch 24/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.9505e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00004\n",
      "Epoch 25/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.1354e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00004\n",
      "Epoch 26/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.1716e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00004\n",
      "Epoch 27/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.2723e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00004\n",
      "Epoch 28/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.0351e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00004\n",
      "Epoch 29/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.6858e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00004\n",
      "Epoch 30/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.7413e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00004\n",
      "Epoch 31/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.0504e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00004\n",
      "Epoch 32/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.0045e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00004\n",
      "Epoch 33/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.5593e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00004\n",
      "Epoch 34/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.4939e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00004\n",
      "Epoch 35/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.4459e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00004\n",
      "Epoch 36/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.7747e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00004\n",
      "Epoch 37/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.4300e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00004\n",
      "Epoch 38/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.9740e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00004\n",
      "Epoch 39/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.5495e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00004\n",
      "Epoch 40/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.4858e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00004\n",
      "Epoch 41/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.4935e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00004\n",
      "Epoch 42/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.3140e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00004\n",
      "Epoch 43/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.9952e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00004\n",
      "Epoch 44/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.2029e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00004 to 0.00004, saving model to weights.hdf5\n",
      "Epoch 45/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.7300e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00004\n",
      "Epoch 46/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.6918e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00004\n",
      "Epoch 47/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.3825e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00004\n",
      "Epoch 48/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.7097e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00004\n",
      "Epoch 49/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.2675e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00004\n",
      "Epoch 50/2500\n",
      " - 2s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.8765e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00004\n",
      "Epoch 51/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.8107e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00004\n",
      "Epoch 52/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.0128e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00004 to 0.00004, saving model to weights.hdf5\n",
      "Epoch 53/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.2590e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00004\n",
      "Epoch 54/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.3886e-05 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00004\n",
      "Epoch 55/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.1237e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00004\n",
      "Epoch 56/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.3891e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00004\n",
      "Epoch 57/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.9435e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00004\n",
      "Epoch 58/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.1895e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00004\n",
      "Epoch 59/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.5203e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00004\n",
      "Epoch 60/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.4928e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00004\n",
      "Epoch 61/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.0816e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00004\n",
      "Epoch 62/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.0344e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00004\n",
      "Epoch 63/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.5277e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00004\n",
      "Epoch 64/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.9132e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00004\n",
      "Epoch 65/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.7730e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00004 to 0.00004, saving model to weights.hdf5\n",
      "Epoch 66/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.9540e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00004\n",
      "Epoch 67/2500\n",
      " - 2s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.4992e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00004\n",
      "Epoch 68/2500\n",
      " - 2s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.7261e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00004\n",
      "Epoch 69/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.0227e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00004\n",
      "Epoch 70/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.1788e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00004\n",
      "Epoch 71/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.2456e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00004\n",
      "Epoch 72/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.1404e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00004\n",
      "Epoch 73/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.5701e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00004\n",
      "Epoch 74/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.1315e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00004\n",
      "Epoch 75/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.9808e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00004\n",
      "Epoch 76/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.5170e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00004\n",
      "Epoch 77/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.5613e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00004\n",
      "Epoch 78/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.1945e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00004\n",
      "Epoch 79/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.2564e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00004\n",
      "Epoch 80/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.2497e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00004\n",
      "Epoch 81/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.2203e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00004\n",
      "Epoch 82/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.0923e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00004\n",
      "Epoch 83/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.8050e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00004\n",
      "Epoch 84/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.5806e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00004\n",
      "Epoch 85/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.3931e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00004\n",
      "Epoch 86/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.5618e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00004\n",
      "Epoch 87/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.1711e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00004\n",
      "Epoch 88/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.2784e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00004\n",
      "Epoch 89/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.1160e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00004\n",
      "Epoch 90/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.3425e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00004\n",
      "Epoch 91/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.2902e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00004\n",
      "Epoch 92/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.1204e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00004\n",
      "Epoch 93/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.8134e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00004\n",
      "Epoch 94/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.7935e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00004\n",
      "Epoch 95/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.2357e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00004 to 0.00003, saving model to weights.hdf5\n",
      "Epoch 96/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.4857e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00003\n",
      "Epoch 97/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.9465e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00003\n",
      "Epoch 98/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.3746e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00003\n",
      "Epoch 99/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.4190e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00003\n",
      "Epoch 100/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.2816e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00003\n",
      "Epoch 101/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.5044e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00003\n",
      "Epoch 102/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.2112e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00003\n",
      "Epoch 103/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.4408e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00003\n",
      "Epoch 104/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 7.1394e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00003\n",
      "Epoch 105/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.4915e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00003\n",
      "Epoch 106/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.9940e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00003\n",
      "Epoch 107/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.3321e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00003\n",
      "Epoch 108/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.2223e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00003\n",
      "Epoch 109/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.2408e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00003\n",
      "Epoch 110/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.9194e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00003\n",
      "Epoch 111/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.0508e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00003\n",
      "Epoch 112/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.7706e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00003\n",
      "Epoch 113/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.7224e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00003\n",
      "Epoch 114/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 6.5333e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00003\n",
      "Epoch 115/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.5965e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00003\n",
      "Epoch 116/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.7981e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00003\n",
      "Epoch 117/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.0850e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00003\n",
      "Epoch 118/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 9.2538e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00003\n",
      "Epoch 119/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 3.9067e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00003\n",
      "Epoch 120/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.2391e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00003\n",
      "Epoch 121/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 2.6779e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00003\n",
      "Epoch 122/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 5.4222e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00003\n",
      "Epoch 123/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 4.6165e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00003\n",
      "Epoch 124/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 1.7038e-04 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00003\n",
      "Epoch 125/2500\n",
      " - 1s - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 8.9055e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00003\n",
      "Epoch 00125: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2018d9cf390>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "model.fit(train_X[::timestep], train_y[::timestep],\n",
    "          batch_size=4,\n",
    "          epochs=2500,\n",
    "          verbose=2, \n",
    "          validation_data=(valid_X[::timestep],valid_y[::timestep]), \n",
    "          callbacks=[checkpointer, early_stopping, history], \n",
    "          shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
